{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color naming acc. evaluator\n",
    "1. Prepare image VQA dataset (Original Image)\n",
    "2. Load Model, and set up the CVD simulator\n",
    "3. Batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./color_150k.json\"\n",
    "MODEL_PATH = \"./Qwen3-VL-8B-Instruct\"\n",
    "CVD_TYPE = \"Deuteranomaly\"\n",
    "CVD_SEVERITY = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "# 如果是第一次运行，需要下载以下资源（只需运行一次）\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "class ColorSentenceEvaluator:\n",
    "    def __init__(self):\n",
    "        # 定义颜色词表\n",
    "        self.selected_colors = {\n",
    "            \"red\", \"green\", \"blue\", \"yellow\", \"orange\", \"purple\",\n",
    "            \"pink\", \"brown\", \"gray\", \"black\", \"white\"\n",
    "        }\n",
    "\n",
    "    def _extract_color_object_pairs(self, sentence):\n",
    "        \"\"\"\n",
    "        提取句子中的颜色-物体对，如 {\"red\": \"car\", \"yellow\": \"wing\"}。\n",
    "        规则：按标点与连词分句 -> 在每个子句中找第一个颜色词 -> 取其后的第一个名词\n",
    "        \"\"\"\n",
    "        pairs = {}\n",
    "        # 拆分子句\n",
    "        clauses = re.split(r'[,.]| and | but ', sentence)\n",
    "        for clause in clauses:\n",
    "            words = word_tokenize(clause)\n",
    "            tagged = pos_tag(words)  # [(word, POS), ...]\n",
    "\n",
    "            color = None\n",
    "            obj = None\n",
    "            for i, (word, pos) in enumerate(tagged):\n",
    "                w_lower = word.lower()\n",
    "                if color is None and w_lower in self.selected_colors:\n",
    "                    color = w_lower\n",
    "                    # 在后面寻找第一个名词（NN/NNS）\n",
    "                    for j in range(i + 1, len(tagged)):\n",
    "                        if tagged[j][1] in (\"NN\", \"NNS\", \"NNP\"):\n",
    "                            obj = tagged[j][0].lower()\n",
    "                            break\n",
    "                    break\n",
    "            if color and obj:\n",
    "                pairs[color] = obj\n",
    "        return pairs\n",
    "\n",
    "    def evaluate(self, predict_sentence, ground_truth_sentence):\n",
    "        \"\"\"\n",
    "        比较预测句与参考句中颜色-物体对的匹配程度，返回准确率(0~1)\n",
    "        \"\"\"\n",
    "        gt_pairs = self._extract_color_object_pairs(ground_truth_sentence)\n",
    "        pred_pairs = self._extract_color_object_pairs(predict_sentence)\n",
    "\n",
    "        if not gt_pairs:\n",
    "            return 1.0 if not pred_pairs else 0.0\n",
    "\n",
    "        correct = sum(\n",
    "            1 for c, o in gt_pairs.items()\n",
    "            if c in pred_pairs and pred_pairs[c] == o\n",
    "        )\n",
    "        return correct / len(gt_pairs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "evaluator = ColorSentenceEvaluator()\n",
    "\n",
    "gt = \"There is a red car, equipped with a yellow wing.\"\n",
    "pred = \"A red car with a yellow spoiler.\"\n",
    "\n",
    "score = evaluator.evaluate(pred, gt)\n",
    "print(\"Color accuracy:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install colour-science\n",
    "from colour.blindness import matrix_cvd_Machado2009\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def RGB_to_sRGB(RGB):\n",
    "    '''RGB to sRGB, value 0.0-1.0(NOT 0-255)'''\n",
    "    sRGB = np.ones_like(RGB)\n",
    "    mask = RGB > 0.0031308\n",
    "    sRGB[~mask] = 12.92*RGB[~mask]\n",
    "    sRGB[mask] = 1.055 * RGB[mask]**(1 / 2.4) - 0.055\n",
    "    return sRGB\n",
    "\n",
    "def sRGB_to_RGB(srgb_img):\n",
    "    ''' Gamma correction of sRGB photo from camera  \n",
    "        value 0.0-1.0(NOT 0-255)\n",
    "    Ref: http://brucelindbloom.com/Eqn_RGB_to_XYZ.html \n",
    "    '''\n",
    "    RGB = np.ones_like(srgb_img)\n",
    "    mask = srgb_img < 0.04045\n",
    "    RGB[mask] = srgb_img[mask]/12.92\n",
    "    RGB[~mask] = ((srgb_img[~mask]+0.055)/1.055)**2.4\n",
    "    return RGB\n",
    "\n",
    "def im_dot(H_mat,im):\n",
    "    '''input: h*w*3, 0.0-1.0 np array'''\n",
    "    h,w,d = im.shape\n",
    "    im = sRGB_to_RGB(im)  # convert to RGB, value 0.0-1.0\n",
    "    im1 = im.reshape(-1,d)\n",
    "    im_dst1 = im1 @ H_mat.T\n",
    "    # im_dst1 = cvd_simulation_tritran(im1)\n",
    "    im_dst = im_dst1.reshape(h,w,d)\n",
    "    im_dst = RGB_to_sRGB(im_dst)  # convert to sRGB, value 0.0-1.0\n",
    "    im_dst[im_dst>1] = 1.\n",
    "    im_dst[im_dst<0] = 0.\n",
    "    return im_dst\n",
    "class cvdSimulateNetMarchado():\n",
    "    def __init__(self,cvd_type='Deuteranomaly',severity=1.0):\n",
    "        \"\"\" 模拟人眼对颜色的感知.\n",
    "        Args:\n",
    "            cvd_type (str, optional): 色盲类型. Defaults to 'Deuteranomaly'. Protanomaly, Deuteranomaly\n",
    "            severity (float, optional): 色盲 Severity. Defaults to 1.0.\n",
    "        \"\"\"\n",
    "        self.cvd_type = cvd_type\n",
    "        self.mat = matrix_cvd_Machado2009(cvd_type, severity)\n",
    "    \n",
    "    def __call__(self,im):\n",
    "        '''\n",
    "        input: h*w*3, Image\n",
    "        output: PIL Image\n",
    "        '''\n",
    "        if isinstance(im,Image.Image):\n",
    "            im = np.array(im)/255.\n",
    "        np_out = im_dot(self.mat,im)\n",
    "        out = Image.fromarray((np_out*255).astype(np.uint8))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# 创建自定义的处理器，基于原始tokenizer\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# -----------------------------\n",
    "# 初始化模型和处理器\n",
    "# -----------------------------\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "model = AutoModelForImageTextToText.from_pretrained(MODEL_PATH, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "cvd_tokenizer = AutoProcessor.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# 参考 https://github.com/huggingface/transformers/blob/main/src/transformers/models/qwen3_vl/processing_qwen3_vl.py\n",
    "\n",
    "# 保存原始的图像预处理方法\n",
    "original_process_images = cvd_tokenizer.image_processor.preprocess\n",
    "\n",
    "# 初始化色盲模拟器\n",
    "# cvd_simulator = cvdSimulateNet(cvd_type='protan', cuda=True, batched_input=True)  # 根据需要设置色盲类型\n",
    "cvd_simulator = cvdSimulateNetMarchado(cvd_type=CVD_TYPE,severity=CVD_SEVERITY)\n",
    "\n",
    "def convert_to_LMS(image):\n",
    "    \"\"\"将彩色图像转换为CVD图像。Output: Tensor\"\"\"\n",
    "    # print(image)# debug\n",
    "    if isinstance(image, list):\n",
    "        return [[cvd_simulator(img[0])] for img in image]\n",
    "    else:\n",
    "        return cvd_simulator(Image.open(image).convert(\"RGB\"))\n",
    "\n",
    "def new_process_images(images, **kwargs):\n",
    "    \"\"\"新的图像预处理方法，先转换为LMS图像\"\"\"\n",
    "    # 转换为黑白图像\n",
    "    LMS_images = convert_to_LMS(images)\n",
    "    # 调用原始的预处理方法\n",
    "    return original_process_images(LMS_images, **kwargs)\n",
    "# 替换处理器的预处理方法\n",
    "cvd_tokenizer.image_processor.preprocess = new_process_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 初始化颜色评估器\n",
    "# -----------------------------\n",
    "evaluator = ColorSentenceEvaluator()\n",
    "\n",
    "# -----------------------------\n",
    "# 加载数据集\n",
    "# -----------------------------\n",
    "with open(\"dataset.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "results = []\n",
    "\n",
    "# ==============================\n",
    "# 遍历数据集\n",
    "# ==============================\n",
    "for sample in tqdm(data, desc=\"Evaluating dataset\"):\n",
    "    messages = sample.get(\"messages\", [])\n",
    "    image_path = None\n",
    "    system_prompt = \"\"\n",
    "    gt_turns = []\n",
    "\n",
    "    # 解析多轮结构\n",
    "    for m in messages:\n",
    "        role = m[\"role\"]\n",
    "        if role == \"system\":\n",
    "            system_prompt = m[\"content\"]\n",
    "        elif role == \"user\" and \"images\" in m:\n",
    "            # 保存图像路径\n",
    "            image_path = m[\"images\"][0]\n",
    "        elif role == \"user\":\n",
    "            current_question = m[\"content\"]\n",
    "        elif role == \"assistant\":\n",
    "            current_answer = m[\"content\"]\n",
    "            # 生成一条完整对话样本\n",
    "            if image_path and current_question and current_answer:\n",
    "                gt_turns.append({\n",
    "                    \"system\": system_prompt,\n",
    "                    \"image\": image_path,\n",
    "                    \"question\": current_question,\n",
    "                    \"answer\": current_answer\n",
    "                })\n",
    "\n",
    "    # ==============================\n",
    "    # 对每轮对话分别推理 + 评估\n",
    "    # ==============================\n",
    "    for turn in gt_turns:\n",
    "        img_path = turn[\"image\"]\n",
    "        gt = turn[\"answer\"]\n",
    "        question = turn[\"question\"]\n",
    "\n",
    "        # 构造输入消息（Qwen-VL 格式）\n",
    "        chat_messages = [\n",
    "            {\"role\": \"system\", \"content\": turn[\"system\"]},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \"image\": img_path},\n",
    "                    {\"type\": \"text\", \"text\": question},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # === 模型推理 ===\n",
    "        input_text = cvd_tokenizer.apply_chat_template(chat_messages, add_generation_prompt = True)\n",
    "        inputs = cvd_tokenizer(\n",
    "            img_path,\n",
    "            input_text,\n",
    "            add_special_tokens = False,\n",
    "            return_tensors = \"pt\",\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        # debug\n",
    "        # print(inputs)\n",
    "\n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=256)\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        output_text = cvd_tokenizer.batch_decode(\n",
    "            generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )[0]\n",
    "\n",
    "        # === 颜色准确率计算 ===\n",
    "        score = evaluator.evaluate(output_text, gt)\n",
    "\n",
    "        results.append({\n",
    "            \"id\": sample[\"id\"],\n",
    "            \"question\": question,\n",
    "            \"predict\": output_text,\n",
    "            \"ground_truth\": gt,\n",
    "            \"color_accuracy\": score\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================\n",
    "# 汇总结果\n",
    "# ==============================\n",
    "mean_acc = sum(r[\"color_accuracy\"] for r in results) / len(results)\n",
    "print(f\"\\nAverage color-object accuracy: {mean_acc:.3f} over {len(results)} QA pairs\")\n",
    "\n",
    "with open(\"color_eval_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
